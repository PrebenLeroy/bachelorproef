\chapter{Stand van zaken}
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

%Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet er nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

%Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz. naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\TeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin, gebruik je \texttt{$\backslash${}textcite\{\}}.
%Soms wil je de auteur niet expliciet vernoemen, dan gebruik je \texttt{$\backslash${}autocite\{\}}. In de volgende paragraaf een voorbeeld van elk.

%\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

%proberen meer in detail te treden per aangehaalde case

Tegenwoordig is artificiële intelligentie niet meer weg te denken uit onze maatschappij. Denk hierbij maar aan zelfrijdende auto’s of robotstofzuigers die weten waar het vuil is. Naast deze reeds bekendere voorbeelden, kan je met AI nog veel meer doen. Denk hierbij maar aan spraak- en tekstherkenning. Een voorbeeld hiervan is het al sprekend ingeven van zoekopdrachten op Google. Maar bestaat er ook een mogelijkheid om op deze manier, dus via spraak- of tekstherkenning, code te laten genereren?

Verscheidene bedrijven en organisaties zoals Google en Microsoft experimenteren met code generatie door middel van AI. Meestal gaat het hierbij over de generatie van SQL-query's, maar in de toekomst zou het misschien ook mogelijk zijn om bijvoorbeeld Java-code te laten genereren. 

\textbf{In de volgende secties worden er een aantal cases besproken.}
\section{Microsoft DeepCoder}

In samenwerking met de universiteit van Cambridge, ontwikkelde Microsoft een mechanisme voor het “zelf schrijven van code”. Hierbij werd gebruik gemaakt van artificiële intelligentie en program synthesis. Het mechanisme kreeg de naam DeepCoder. Dat schrijft \textcite{DeepCoder} in een artikel op LinkedIn.

Met DeepCoder zouden mensen, ook al hebben ze geen enkele programmeerachtergrond, werkende code kunnen laten schrijven binnen een paar seconden. DeepCoder kan nu al gebruikt worden voor basis problemen op te lossen.

DeepCoder maakt gebruik van Program Synthesis, waarbij DeepCoder eigenlijk lijnen code “steelt” van werkende software. Daarnaast wordt er bruikbare code gezocht op websites zoals StackOverflow om te gebruiken in de te schrijven code. Eigenlijk volgt Program Synthesis de manier van werken van een programmeur (code opzoeken op het internet), maar doet dat veel sneller. Dit wordt onder andere vermeld in het artikel van \textcite{techcrunch} en het artikel van \textcite{NewScientist}.

Programmeurs hoeven geen schrik te hebben voor hun job. DeepCoder zou in de toekomst kunnen gebruikt worden om het vuile, herhalende werk op te knappen. Programmeurs zouden de eerder moeilijke taken uitvoeren.

\section{Google AutoML}

Naast Microsoft is Google ook bezig met het ontwikkelen van een mechanisme waarbij artificiële intelligentie wordt gebruikt voor de generatie van code. Dit onder de naam “Google AutoML”. Eén van de belangrijkste kenmerken van AutoML, is dat het mechanisme zichzelf altijd tracht te verbeteren. Het is nu al zo ver gekomen dat dit mechanisme betere code kan schrijven dan de programmeurs die het ontwikkeld hebben. Dit werd beschreven door \textcite{greene}.

Google ontwikkelde hun AutoML als oplossing voor het gebrek aan talent bij de AI-programmeurs. De vraag naar gespecialiseerde programmeurs is zo groot geworden, dat AutoML als oplossing werd aangereikt. 

Het systeem voert duizenden simulaties uit om te bepalen welke delen van de code kunnen worden verbeterd, de wijzigingen aan te brengen en de procesadvertentie oneindig door te zetten of totdat het doel is bereikt. 
 
AutoML is nog gloednieuw. Het is ongeveer een jaar geleden voorgesteld. Het vormt de basis voor de volgende generaties in machine-learning.

\section{Salesforce - Seq2SQL}
\label{sec:Salesforce - Seq2SQL}

Het Seq2SQL van Salesforce is een eerder concreet voorbeeld voor code generatie door middel van artificiële intelligentie. Seq2SQL is een mechanisme dat, door middel van AI en reinforcement learning\footnote{Het is een mechanisme dat in staat is om uit eigen ervaringen te leren. Wanneer het mechanisme iets goed doet, wordt het hiervoor beloond. Het zal die stappen blijven uitvoeren waarvoor het de meeste beloningen heeft gekregen. Het doel is om het meeste beloningen te verkrijgen.}, gestructureerde SQL-query’s kan genereren. Hier werd grondig onderzoek naar gedaan. Dit valt allemaal te lezen in de paper, opgesteld door \textcite{seq2sqlPaper}.

Tegenwoordig wordt data bijna altijd opgeslagen in een relationale databank. Gegevens kunnen enkel via query’s, eigen aan de vooropgestelde SQL-syntax, opgehaald worden. Seq2SQL werkt anders.

Via dit model kunnen er vanuit natuurlijke taal, SQL-query’s gegenereerd worden. Hiervoor wordt gebruik gemaakt van neurale netwerken. Deze neurale netwerken worden zo geprogrammeerd dat deze gelijkaardig werken als het menselijke brein. 

Het Seq2SQL-model maakt volgens de paper (\textcite{seq2sqlPaper}) gebruik van het Seq2Seq-model. Volgens de basistheorie, beschreven door \textcite{drnn}, bestaat zo’n model uit 2 belangrijke onderdelen, een encoder en een decoder. Beiden zijn recurrente lagen van het neurale netwerk\footnote{De mogelijkheid om verder te bouwen op eerdere typen netwerken met ingangsvectoren van een vaste grootte en uitgangsvectoren – Definitie door \textcite{rnn}.}. Er wordt, door de encoder, een invoerreeks verwerkt tot een vaste representatie. De uitkomst van de encoder dient als context voor de decoder. Deze verwerkte informatie wordt hier dan gedecodeerd tot een bepaalde uitvoerreeks. In figuur … wordt er een visueel beeld gegeven van dit model. Dit voorbeeld wordt ook door \textcite{drnn} gegeven.

Een SQL-query bestaat meestal uit drie onderdelen. Als eerste component heeft u de aggregatie-operator (zoals COUNT en SUM). Dit geeft een samenvatting weer van de rijen die door de SQL-query worden aangeroepen. Ook kan het mogelijk zijn dat er geen operator meegegeven wordt. Het tweede component is de kolom waarop de query dient uitgevoerd te worden. Het derde en laatste component is de WHERE-clause. Dit geeft aan op welke rij(en) er dient gefilterd te worden. Seq2SQL zorgt ervoor dat een vraag direct in zo’n vorm kan gegoten worden (zie figuur …).

Het augmented pointer network is een zeer belangrijk netwerk voor Seq2SQL. Dit netwerk genereert woord voor woord de SQL-query van een invoerreeks. De uitkomst van dit netwerk mag dan wel een SQL-query zijn, maar dit is niet volledig volgens de reeds beschreven vorm. Daarvoor dient dan Seq2SQL. Eerst wordt door het netwerk de aggregatie-operator gezocht in de invoerreeks. Deze waarde kan eveneens null zijn, wanneer er geen aggregatie voorgeschreven is. Voor het volgende onderdeel zoekt het netwerk naar de kolom waarop het de query dient uit te voeren. Als laatste wordt via een pointer network gezocht naar de condities waarop eventueel gefilterd kan worden. De twee eerste componenten worden gesuperviseerd door middel van cross entropy\footnote{Cross entropy is het aantal bits dat nodig is om symbolen uit de verzameling p te encoderen, gebruik makend van de foutieve verzameling q – Definitie door \textcite{rdp}.} loss. Het derde component wordt getraind door middel van policy reïnforcement learning. Hiermee wordt de ongeordende aard van de query aangepakt.

Seq2SQL wordt in deze paper van \textcite{seq2sqlPaper} niet enkel theoretisch aangehaald. Er wordt ook een experiment beschreven waarbij het algoritme wordt uitgetest inzake performantie.  Voor deze experimenten werd gebruik gemaakt van de WikiSQL-dataset (\textcite{wikisql}). Deze dataset is een verzameling van de meest gebruikte SQL-query’s die gebruikt werden tijdens de zoekopdrachten op Wikipedia. WikiSQL wordt gebruikt om het model van Seq2SQL te trainen. De broncode kan gevonden worden op de Github-repository van \textcite{seq2sql}.

Uit de resultaten van de uitgevoerde experimenten blijkt dat de performantie het grootst is bij het uitvoeren van het volledige Seq2SQL algoritme. Dit dus met het toepassen van reïnforcement learning. Seq2SQL zonder het gebruik van reïnforcement learning levert een performantie op die zo’n 2,7\% lager is dan het volledige model. De volledige resultaten worden voorgesteld in tabel …. 

Enkele conclusies die hierbij getrokken kunnen worden:
\begin{itemize}
	\item Het beperken van de uitvoerruimte leidt tot meer nauwkeurige omstandigheden.
	\item Het toepassen van de juiste SQL-structuur zorgt voor minder ongeldige queries.
	\item Reïnforcement learning zorgt ervoor dat de WHERE-clauses van een goede kwaliteit zijn.
\end{itemize}

\section{SQLNet}

Naast Seq2SQL, bestaat er ook SQLNet. Dit mechanisme werkt op een ongeveer gelijkaardige manier als Seq2SQL, maar hier wordt geen reinforcement learning toegepast. De huidige manier van werken (het belonen van het model) is niet eerder beperkt. Daarom is het nodig dat er verandering komt. SQLNet komt hier dus met de oplossing.

SQLNet werkt volgens een schetsmatige benadering waarbij een schets een afhankelijkheidsgrafiek bevat. Op die manier kan een voorspelling gedaan worden wanneer eerdere, afhankelijke voorspellingen in overweging te nemen. 

Maar hoe werkt dat nu precies? SQLNet wordt in de paper van \textcite{sqlnetPaper} grondig voorgesteld. Het basisidee van SQLNet is het gebruik van een schetsmatige voorstelling die overeenkomt met de SQL-grammatica. Het mechanisme dient enkel de plaatsen in de schets op te vullen. De schets is zo opgebouwd, dat het mogelijk is om alle soorten query’s te kunnen genereren.

Het gebruikmaken van zo’n schets heeft als voordeel dat de orderaangelegenheden die kunnen voorkomen in een sequence-to-sequence-model (zie  sectie \ref{sec:Salesforce - Seq2SQL} ) te voorkomen. Dit komt omdat de schets de afhankelijkheid van de voorspellingen vastlegt. 

Net als bij Seq2SQL wordt voor dit model gebruik gemaakt van de WikiSQL-dataset voor het uitvoeren van de experimenten en het trainen van het model. Zo kan er bewezen worden dat door het uitvoeren van het SQLNet-mechanisme, 9 tot 13 procent beter werkt dan een ander mechanisme. De volledige source code kan gevonden worden op de Github-repository van \textcite{sqlnet}.

\section{Algoritme voor transformatie van tekst naar SQL-query's (NLIDBS)}

Zoals vermeld bij Seq2SQL, worden grote hoeveelheden data opgeslagen in relationele databanken. Een groot nadeel hierbij is dat de meeste mensen de kennis niet hebben inzake SQL om te communiceren met de databank. Een oplossing hiervoor zou zijn dat mensen in hun eigen taal zouden kunnen communiceren met de databank. Deze oplossing staat beschreven in het artikel van \textcite{nlidbs}.

Onderzoekers hebben een intelligente interface ontwikkeld die natuurlijke taalquery’s (zoals “Geef een lijst van de laatste 5 presidenten van Amerika.”) omzet naar SQL-query’s. Er wordt hier gebruik gemaakt van semantische matchingtechnieken. Hierbij wordt er rekening gehouden met de betekenis van de woorden in de opgegeven zoekstring. 

Er worden een aantal stappen uitgevoerd om tot de juiste query uit te komen. Door deze query dan uit te voeren op de databank, komt het juiste antwoord naar boven. 

Enkele van de stappen, welke gebruikt worden om vanuit natuurlijke taal SQL-query’s te genereren:

\begin{itemize}
\item Hoofdletters naar kleine letters omzetten
\item Tokenisatie
\item Het verwijderen van extra/stop woorden
\item Classificatie van de overgebleven woorden
\item Het bouwen van de query
\item \dots
\end{itemize}

Er kan een gelijkaardig algoritme teruggevonden worden op de Github-repository van \textcite{nlidb}.

\section{Microsoft Research - NL2Prog}

Eigenlijk is het doel van het onderzoek, beschreven in de paper NL2Prog, gelijkaardig aan het onderzoek uitgevoerd in Seq2SQL en in NLIDBS. De meeste mensen zijn niet in staat om via query's te communiceren met de databank wegens geen (of alleszins te weinig) programmeerkennis. De mens wil instaat zijn op een normale manier te kunnen communiceren met de databank, dus eigenlijk via hun eigen taal. Hiervoor probeert men een oplossing te geven in de paper van \textcite{nl2prog}.		

Voor dit model wordt gebruik gemaakt van een deep sequence-to-sequence model. Hierbij wordt als decoder een eenvoudig type systeem van SQL-expressies gebruikt, welke gebruikt worden om de uitvoervoorspelling te structureren. Door middel van het type kopieert de decoder een mogelijke output van de inputstring. Dit met behulp van een op aandacht-gebaseerd kopieermechanisme, ofwel genereerd het een query vanuit een vast vocabulair.

Zoals bij Seq2SQL en SQLNet wordt ook dit model geëvalueerd op de WikiSQL dataset (\textcite{wikisql}). Via gesuperviseerd leren kan aangetoond worden dat het model van NL2Prog, beter presteert dat de eerst genoemde mechanismen. 

\section{Primary Objects - AI Programmer}

AI Programmer is het eerste machine learning systeem dat in staat is om volledige code te genereren. De mens dient maar weinig hulp eraan te bieden om het te doen slagen. Door middel van artificiële intelligentie en enkele genetische algoritmes, is AI Programmer in staat om een aantal kleine programmatjes te produceren. 

Deze kleine programmatjes zijn bijvoorbeeld de volgende:
\begin{itemize}
	\item Hello World
	\item Fibonnaci
	\item Optellen en Aftrekken
	\item \dots
\end{itemize}

AI Programmer is een zelflerend mechanisme. Het is een AI genetisch algoritme dat zichzelf altijd tracht te verbeteren.

De computer alle soorten programma’s laten creëren is het achterliggend idee voor de creatie van AI Programmer. Het ultieme doel is dan weer om computerprogramma’s te genereren voor het oplossen van problemen.

\textbf{In de volgende secties wordt onder andere gesproken over de technieken die achter de mechanismen zit. Daarnaast wordt er ook informatie aangehaald over de meest voorkomende programmeertaal uit de cases.}
\section{Vierde generatie programmeertalen}

Zoals vermeld bij de opgegeven cases, worden in de meeste gevallen SQL-query’s gegenereerd. Maar wat voor soort programmeertaal is SQL eigenlijk? Wel, SQL behoort tot de groep van de vierde generatie programmeertalen. 

Maar wat is er zo speciaal aan deze generatie programmeertalen? Volgens \textcite{fourthgenpl} behoren de 4GL tot de talen die het dichtst aanleunen tegen de natuurlijke taal. Ze hebben het voordeel van onder andere sneller te kunnen verlopen en de kosten voor de ontwikkeling te verminderen.

Vierde generatie programmeertalen zijn de enige talen die vaak in contact komen met grote hoeveelheden aan data. Onder de vierde generatie programmeertalen kan je daarom volgende domeinen terugvinden:

\begin{itemize}
	\item Databasequery’s
	\item Rapporteringen
	\item Gegevensmanipulatie
	\item \dots
\end{itemize}

Het is dus via zo’n talen mogelijk om data op te vragen uit tabellen, deze aan te passen of mooi uit te schrijven in een rapport.

Naast SQL behoren onder andere volgende programmeertalen ook tot de vierde generatie: R, S, ABAP, Oracle Forms en Bizagi.

\section{Neurale netwerken}

Achter alle mechanismen om code te laten genereren, zit er artificiële intelligentie. Meer bepaald artificiële neurale netwerken. Maar wat zijn neurale netwerken? 

Wanneer iemand denkt aan neurale netwerken, wordt er meer bepaald gedacht aan het menselijke brein. Het menselijk brein bestaat uit een groot aantal neuronen. Deze neuronen werken samen door middel van elektrochemische signalen. Bij artificiële neurale netwerken probeert men alle kenmerken van een menselijk neuron samen te voegen in een wiskundig model. Over artificiële neurale netwerken valt er nog meer te lezen in de Hogeschool Cursus AI door \textcite{cursusAI} en in het artikel van \textcite{techpulse}.

Hoe werken artificiële neurale netwerken nu eigenlijk? 

Neurale netwerken worden getraind om te kunnen werken. Denk bijvoorbeeld aan het herkennen van nummers uit een lijst. Of zoals Facebook, die gezichten op foto’s herkend en vraagt om eventueel deze herkende mensen te taggen in de bewuste foto’s. 

Het voorbeeld dat wordt omschreven in het artikel op de website van tweakers (\textcite{tweakers}) gaat over het herkennen van handgeschreven getallen uit een foto. Deze foto of afbeelding (meestal 28 bij 28 pixels) wordt gebruikt als input voor het neurale netwerk. In de datasets die gebruikt worden voor het netwerk te trainen, zitten er ook afbeeldingen van 28 bij 28 pixels met handgeschreven cijfers op. De mens herkent makkelijk de cijfers in de afbeeldingen, door te kijken naar de grijswaarden in de pixels. Het neurale netwerk moet wel gaan rekenen, daarom worden aan alle ingaven (28 x 28 = 784) een waarde tussen 0 en 1 gegeven. Een neuraal netwerk is NIET binair, maar wel analoog. 

De data uit deze eerste laag neuronen, wordt doorgestuurd naar de tweede, verborgen, laag. Dit is een veel kleinere laag neuronen. In deze laag wordt er een bepaald gewicht gegeven aan de data van de input grijswaarden. De data uit de tweede laag krijgt dus ook weer een waarde tussen 0 en 1. Deze waarden worden dan doorgegeven aan de uitvoer neuronen. Het neuron dat het dichtste aanleunt tegen 1, geeft het cijfer aan dat het net “gezien” zou hebben. 

Een neuraal netwerk zou ook kunnen bestaan uit meerdere lagen neuronen. Voor de simpliciteit werd in dit voorbeeld maar één tussenlaag gebruikt.

Maar hoe worden neurale netwerken nu getraind? Voor het trainen van een neuraal netwerk, kan men één van de volgende vijf optimalisatiealgoritmen toepassen, welke beschreven zijn door \textcite{neuraldesigners}.

\begin{description}
	\item[Gradient Descent] Gradient Descent is het makkelijkste algoritme voor het trainen van een neuraal netwerk. Het is een eerste orde iteratief optimalisatie algoritme voor het vinden van een minimum van een functie. Door eerst voorwaartse propagatie uit te voeren en daarna achterwaartse propagatie, kan men de gradiënt berekenen. Het is wel de bedoeling dat de gehele training dataset onderzocht wordt. Door het uitvoeren van het gradiënt descent algoritme, kan men al een idee krijgen in welke richting de gewichten zich zouden aanpassen.
	\item[Methode van Newton] Gradiënt Descent is dan wel een eerste orde algoritme, de methode van Newton is een tweede orde algoritme. Het maakt gebruik van de Hessiaan\footnote{Dit is een matrix van de tweede orde partiële afgeleiden van een functie.} van de te minimaliseren functie. Deze functie wordt gebruikt om een betere trainingsrichting te vinden door de tweede orde afgeleiden van de verliesfunctie te gebruiken.
	\item[Conjugate gradient] De conjugate gradiënt is een vorm tussen de gradiënt descent en de methode van Newton. Via deze methode is het mogelijk om de normaal gezien langzame convergentie te versnellen (dit is zo bij gradiënt descent). Daarnaast wordt het werken met de Hessiaan matrix en alle andere benodigdheden van de methode van Newton ook vermeden.
	\item[Quasi-Newton-methode] De methode van Newton is duur in uitvoer. Er zijn veel bewerkingen nodig om voor die methode alles te berekenen. De quasi-Newton methode is een beter alternatief. Het is ontwikkeld om een antwoord te bieden alle nadelen van de methode van Newton. Bij deze methode wordt er per iteratie van het algoritme, een benadering gegeven op de inverse Hessiaan. Hiervoor worden enkel de eerste afgeleiden van de verliesfunctie gebruikt.
	\item[Het algoritme van Levenberg-Marquardt] Dit algoritme is speciaal ontworpen om te werken met verliesfuncties die de vorm aannemen van een som kwadratische fouten. In plaats van de Hessiaan-matrix te gebruiken, wordt er gebruik gemaakt van de Jacobi-matrix\footnote{De Jacobi-matrix van een functie is de matrix van de eerste-orde partiële afgeleiden van een functie.}.
\end{description}

Neurale netwerken zijn belangrijk voor het genereren van code uit tekst of uit natuurlijke taal. Deze neurale netwerken worden getraind om woorden te herkennen uit de gestelde vragen. Door middel van die woorden wordt er via allerhande mechanismen en algoritmen code gegenereerd.
